{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24b6a8d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'excludes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3708\\3194541814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# Create a BookIndexer object and index the pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mbook_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBookIndexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mbook_indexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3708\\3194541814.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, page_files, exclude_file, index_file)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcludes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excludes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Read the exclude words from file and store in a set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3708\\3194541814.py\u001b[0m in \u001b[0;36mread_excludes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcludes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mexcludes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Read a single page file and return the set of unique words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'excludes' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "# Define a class to read and index the pages of a book\n",
    "class BookIndexer:\n",
    "    def __init__(self, page_files, exclude_file, index_file):\n",
    "        self.page_files = page_files\n",
    "        self.exclude_file = exclude_file\n",
    "        self.index_file = index_file\n",
    "        self.index = {}\n",
    "        self.excludes = self.read_excludes()\n",
    "    \n",
    "    # Read the exclude words from file and store in a set\n",
    "    def read_excludes(self):\n",
    "        excludes = set()\n",
    "        with open(self.exclude_file) as f:\n",
    "            for word in f.read().split():\n",
    "                excludes.add(word)\n",
    "        return excludes\n",
    "    \n",
    "    # Read a single page file and return the set of unique words\n",
    "    def read_page(self, page_file):\n",
    "        with open(page_file) as f:\n",
    "            words = f.read().split()\n",
    "        # Remove exclude words and return unique set of words\n",
    "        return set(filter(lambda x: x not in self.excludes, words))\n",
    "    \n",
    "    # Index all pages and write the index to the output file\n",
    "    def index_pages(self):\n",
    "        # Iterate through each page file and index its unique words\n",
    "        for page_num, page_file in enumerate(self.page_files, start=1):\n",
    "            page_words = self.read_page(page_file)\n",
    "            # Iterate through each unique word and add its page to the index\n",
    "            for word in page_words:\n",
    "                word = self.get_filtered_word(word)\n",
    "                if word == \"\":\n",
    "                    continue\n",
    "                if word not in self.index:\n",
    "                    self.index[word] = set()\n",
    "                self.index[word].add(page_num)\n",
    "        \n",
    "        # Write the index to the output file\n",
    "        with open(self.index_file, 'w') as f:\n",
    "            for word in sorted(self.index.keys()):\n",
    "                pages = ','.join(map(str, sorted(self.index[word])))\n",
    "                f.write(f\"{word} : {pages}\\n\")\n",
    "    def get_filtered_word(self, word):\n",
    "        word = word.lower()\n",
    "        retracted_word = \"\"\n",
    "        for letter in word:\n",
    "            if letter.isalpha():\n",
    "                retracted_word += letter\n",
    "        if retracted_word in word:\n",
    "            return retracted_word\n",
    "        return \"\"\n",
    "# Define the input and output files\n",
    "page_files = ['Page1.txt', 'Page2.txt', 'Page3.txt']\n",
    "exclude_file = 'exclude-words.txt'\n",
    "index_file = 'index1.txt'\n",
    "\n",
    "# Create a BookIndexer object and index the pages\n",
    "book_indexer = BookIndexer(page_files, exclude_file, index_file)\n",
    "book_indexer.index_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sort_index(self):\n",
    "        keys = list(self.index.keys())\n",
    "        values = list(self.index.values())\n",
    "        sorted_value_index = np.argsort(keys)\n",
    "        sorted_dict = OrderedDict()\n",
    "        for i in sorted_value_index:\n",
    "            sorted_dict[keys[i]] =  values[i]\n",
    "        \n",
    "        return sorted_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
